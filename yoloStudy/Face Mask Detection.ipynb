{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face Mask Detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMdH2kRwlRclWXcAKdnFzSN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"09sKjcOF85r_"},"source":["https://www.kaggle.com/ayushimishra2809/face-mask-detection"]},{"cell_type":"markdown","metadata":{"id":"PYVNcXP7kMj5"},"source":["<h2> import libraries </h2>"]},{"cell_type":"code","metadata":{"id":"BtfrIMV6fiE0","executionInfo":{"status":"ok","timestamp":1613407011399,"user_tz":-540,"elapsed":614,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}}},"source":["import numpy as np \n","import pandas as pd \n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","import matplotlib.patches as patches\n","import tensorflow as tf\n","from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n","from keras.models import Sequential"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPnpmbtygI0j","executionInfo":{"status":"ok","timestamp":1613407015191,"user_tz":-540,"elapsed":2730,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}},"outputId":"bb21b82d-b53a-4784-ec29-e1bfe29ad61e"},"source":["pip install mtcnn"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mtcnn in /usr/local/lib/python3.6/dist-packages (0.1.0)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V4DOTG5giEgi","executionInfo":{"status":"ok","timestamp":1613407017978,"user_tz":-540,"elapsed":585,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}}},"source":["from mtcnn.mtcnn import MTCNN   # face detection algorithm"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xE_AZWTPkUQF"},"source":["<h2> loading datasets </h2>"]},{"cell_type":"code","metadata":{"id":"2bs5nrUmiF5J","executionInfo":{"status":"ok","timestamp":1613407067517,"user_tz":-540,"elapsed":584,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}}},"source":["images=os.path.join(\"/Medical mask/Medical mask/Medical Mask/images\")\n","annotations=os.path.join(\"/Medical mask/Medical mask/Medical Mask/annotations\")\n","train=pd.read_csv(os.path.join(\"train.csv\"))\n","submission=pd.read_csv(os.path.join(\"submission.csv\"))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"dV4h9t7FiJbF","executionInfo":{"status":"ok","timestamp":1613407072954,"user_tz":-540,"elapsed":621,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}},"outputId":"d1a83923-e72d-48fa-d087-b1f2829920d2"},"source":["print(len(train))\n","train.head()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["15412\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>y1</th>\n","      <th>y2</th>\n","      <th>classname</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2756.png</td>\n","      <td>69</td>\n","      <td>126</td>\n","      <td>294</td>\n","      <td>392</td>\n","      <td>face_with_mask</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2756.png</td>\n","      <td>505</td>\n","      <td>10</td>\n","      <td>723</td>\n","      <td>283</td>\n","      <td>face_with_mask</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2756.png</td>\n","      <td>75</td>\n","      <td>252</td>\n","      <td>264</td>\n","      <td>390</td>\n","      <td>mask_colorful</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2756.png</td>\n","      <td>521</td>\n","      <td>136</td>\n","      <td>711</td>\n","      <td>277</td>\n","      <td>mask_colorful</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6098.jpg</td>\n","      <td>360</td>\n","      <td>85</td>\n","      <td>728</td>\n","      <td>653</td>\n","      <td>face_no_mask</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name   x1   x2   y1   y2       classname\n","0  2756.png   69  126  294  392  face_with_mask\n","1  2756.png  505   10  723  283  face_with_mask\n","2  2756.png   75  252  264  390   mask_colorful\n","3  2756.png  521  136  711  277   mask_colorful\n","4  6098.jpg  360   85  728  653    face_no_mask"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"SL_ZRwWAiL7g","executionInfo":{"status":"ok","timestamp":1613407078244,"user_tz":-540,"elapsed":787,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}},"outputId":"5f59b0ef-51f9-441d-8410-83dc052916ac"},"source":["print(len(submission))\n","submission.head()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["8142\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>y1</th>\n","      <th>y2</th>\n","      <th>classname</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1800.jpg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1800.jpg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1800.jpg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1799.jpg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1799.jpg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  x1  x2  y1  y2  classname\n","0  1800.jpg NaN NaN NaN NaN        NaN\n","1  1800.jpg NaN NaN NaN NaN        NaN\n","2  1800.jpg NaN NaN NaN NaN        NaN\n","3  1799.jpg NaN NaN NaN NaN        NaN\n","4  1799.jpg NaN NaN NaN NaN        NaN"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"PG18Tj64iP1t","executionInfo":{"status":"error","timestamp":1613407082350,"user_tz":-540,"elapsed":621,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}},"outputId":"9bff0f21-5f2c-4dc8-eb31-a9e0fd8be33c"},"source":["len(os.listdir(images))"],"execution_count":18,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-914a2cdaa368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Medical mask/Medical mask/Medical Mask/images'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"poG-aXtCiSNS","executionInfo":{"status":"error","timestamp":1613407300007,"user_tz":-540,"elapsed":620,"user":{"displayName":"지연","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gglewogr24AjLvqHq_eS8cPI28v3jSEm6bZlGMelw=s64","userId":"13150378889046189722"}},"outputId":"a5d3ef81-30cd-4b13-ab78-7d64ae70f523"},"source":["a=os.listdir(images)\n","b=os.listdir(annotations)\n","a.sort()\n","b.sort()\n","print(len(b),len(a))"],"execution_count":19,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-2818285b8059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Medical mask/Medical mask/Medical Mask/images'"]}]},{"cell_type":"code","metadata":{"id":"l0Zzrv3xiTm4"},"source":["train_images=a[1698:]\n","test_images=a[:1698]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_kYo7NwiXLP"},"source":["test_images[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tveBZuEKiY15"},"source":["img=plt.imread(os.path.join(images,test_images[0]))\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amqlxZnfia6w"},"source":["options=['face_with_mask','face_no_mask']\n","train= train[train['classname'].isin(options)]\n","train.sort_values('name',axis=0,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnBqevyPidW7"},"source":["bbox=[]\n","for i in range(len(train)):\n","    arr=[]\n","    for j in train.iloc[i][[\"x1\",'x2','y1','y2']]:\n","        arr.append(j)\n","    bbox.append(arr)\n","train[\"bbox\"]=bbox  \n","def get_boxes(id):\n","    boxes=[]\n","    for i in train[train[\"name\"]==str(id)][\"bbox\"]:\n","        boxes.append(i)\n","    return boxes\n","print(get_boxes(train_images[3]))\n","image=train_images[3]\n","\n","img=plt.imread(os.path.join(images,image))\n","\n","fig,ax = plt.subplots(1)\n","ax.imshow(img)\n","boxes=get_boxes(image)\n","for box in boxes:\n","    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n","    ax.add_patch(rect)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYt3g8B2ifHf"},"source":["image=train_images[5]\n","\n","img=plt.imread(os.path.join(images,image))\n","\n","fig,ax = plt.subplots(1)\n","ax.imshow(img)\n","boxes=get_boxes(image)\n","for box in boxes:\n","    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n","    ax.add_patch(rect)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_Ef_nR5igQ4"},"source":["plt.bar(['face_with_mask','face_no_mask'],train.classname.value_counts())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZI1h3Vrkedw"},"source":["<h2> creating training data </h2>"]},{"cell_type":"code","metadata":{"id":"-othUKf8iks5"},"source":["img_size=50\n","data=[]\n","path='/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'\n","def create_data():\n","       for i in range(len(train)):\n","            arr=[]\n","            for j in train.iloc[i]: # iloc : 행번호 선택\n","                   arr.append(j)\n","            # opencv로 이미지 불러오기\n","            # IMREAD_GRAYSCALE : 칼라이미지 -> gray 색상으로 해석해 이미지 객체 반환\n","            img_array=cv2.imread(os.path.join(images,arr[0]),cv2.IMREAD_GRAYSCALE)\n","            crop_image = img_array[arr[2]:arr[4],arr[1]:arr[3]]\n","            #이미지 크기 조절 : cv2.resize(원본이미지, 결과이미지크기(너비, 높이),보간법)\n","            new_img_array=cv2.resize(crop_image,(img_size,img_size))\n","            data.append([new_img_array,arr[5]])\n","create_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_h1spiU-inZU"},"source":["data[0][0]\n","plt.imshow(data[0][0])  # 이미지 출력"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tWQy90OipcD"},"source":["x=[]\n","y=[]\n","for features, labels in data:\n","    x.append(features)\n","    y.append(labels)\n","from sklearn.preprocessing import LabelEncoder\n","# 학습모델이 해당 데이터를 인지할 수 있도록 데이터 수치화하기\n","lbl=LabelEncoder()  # 라벨인코더 생성\n","y = lbl.fit_transform(y)   # 수치화하기"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QI6AxbUUiqkb"},"source":["# array 재구성\n","x = np.array(x).reshape(-1,50,50,1)\n","# 모든 값이 0~1사이에 있도록 정규화\n","x = tf.keras.utils.normalize(x,axis=1)\n","# one-hot incoding : 10진 정수 -> 2진 바이너리 형식으로 변경\n","# (파라미터로 값 크기만큼 0으로 된 배열을 만들고 파라미터 값 위치에만 1(hot)을 넣어줌)\n","# ex) to_categorial(4);; array([0,0,0,0,1])\n","from keras.utils import to_categorical\n","y = to_categorical(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hE1RO6PYirg5"},"source":["<h2> model fitting </h2>"]},{"cell_type":"code","metadata":{"id":"FaebnIrwitDk"},"source":["from keras.layers import LSTM\n","# 선형회귀모델(y = Wx+B) 만들기\n","# 인공 신경망의 각 층을 순서대로 쌓음\n","model=Sequential()\n","\n","# 합성곱 신경망 구성\n","# conv2D layer : 영상인식에 주로 사용\n","# conv2D(컨볼루션 필터 수, (컨볼루션 커널 행,열), input_shape, activation, strides)\n","# filter : 이미지에서 특징(feature)을 분리해내는 기능\n","# kernel_size : filter의 크기\n","# input_shape : 샘플 수를 제외한 입력 형태(행,열,채널수(흑백=1))\n","# activation : 활성화 함수 설정 (relu = rectifier 함수)\n","# strides : 필터 순회 간격\n","# pooling : feature map으로부터 값을 샘플링해서 정보 압축 - max : 특정영역에서 가장 큰 값을 샘플링\n","model.add(Conv2D(100,(3,3),input_shape=x.shape[1:],activation='relu', strides=2))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","\n","# Dense - 분류\n","# Dense layer : 입출력 모두 연결, 입출력을 각각 연결해주는 가중치 포함\n","# 출력 뉴런(노드)수 50, acvivation 활성화 함수 = relu(은닉층)\n","model.add(Dense(50, activation='relu'))\n","model.add(Dropout(0.2))\n","# 출력 노드 수 2, softmax(확률값으로 다양한 클래스 분류-출력층에 사용)\n","model.add(Dense(2, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjLnSdXaivNO"},"source":["opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n","# 만들어진 모델 컴파일\n","# optimizer : 손실함수 기반으로 네트워크가 어떻게 업데이트 될지 결정\n","# loss : 손실함수, 입력데이터가 출력데이터와 얼마나 일치하는지 평가\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n","# 컴파일한 모델 훈련\n","# 입력데이터와 출력데이터를 인자로 넣고\n","# epochs : 30번 훈련, batch_size : 작업단위 5개씩 잡아서 훈련\n","model.fit(x,y,epochs=30,batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AIffokZ6iwk2"},"source":["detector=MTCNN()\n","img=plt.imread(os.path.join(images,test_images[0]))\n","# 이미지에 얼굴인식\n","face=detector.detect_faces(img)\n","for face in face:\n","        bounding_box=face['box']\n","        x=cv2.rectangle(img,\n","              (bounding_box[0], bounding_box[1]),\n","              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n","              (0,155,255),\n","              10)\n","        plt.imshow(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okJKlixjixq9"},"source":["img=plt.imread(os.path.join(images,test_images[3]))\n","face=detector.detect_faces(img)\n","for face in face:\n","        bounding_box=face['box']\n","        x=cv2.rectangle(img,\n","              (bounding_box[0], bounding_box[1]),\n","              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n","              (0,155,255),\n","              10)\n","        plt.imshow(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8Z4ZiAjizoA"},"source":["detector=MTCNN()\n","test_df=[]\n","for image in test_images:\n","    img=plt.imread(os.path.join(images,image))\n","    faces=detector.detect_faces(img)\n","    test=[]\n","    for face in faces:\n","        bounding_box=face['box']\n","        test.append([image,bounding_box])\n","    test_df.append(test)\n","test=[]\n","for i in test_df:\n","    if len(i)>0:\n","        if len(i)==1:\n","            test.append(i[0])\n","        else:\n","            for j in i:\n","                test.append(j)  \n","sub=[]\n","rest_image=[]\n","for i in test:\n","    sub.append(i[0])\n","for image in test_images:\n","    if image not in sub:\n","        rest_image.append(image) \n","detector=MTCNN()\n","test_df_=[]\n","for image in rest_image:\n","    img=cv2.imread(os.path.join(images,image))\n","    faces=detector.detect_faces(img)\n","    test_=[]\n","    for face in faces:\n","        bounding_box=face['box']\n","        test_.append([image,bounding_box])\n","    test_df_.append(test_) \n","for i in test_df_:\n","    if len(i)>0:\n","        if len(i)==1:\n","            test.append(i[0])\n","        else:\n","            for j in i:\n","                test.append(j)      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8ChFXNmi0rG"},"source":["negative=[]\n","for i in test:\n","    for j in i[1]:\n","        if j<0:\n","            negative.append(i)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TJnPJuAi1_V"},"source":["test_data=[]\n","def create_test_data():\n","            for j in test:\n","                if j not in negative:\n","                    img=cv2.imread(os.path.join(images,j[0]),cv2.IMREAD_GRAYSCALE)\n","                    img=img[j[1][1]:j[1][1]+j[1][3],j[1][0]:j[1][0]+j[1][2]]\n","                    new_img=cv2.resize(img,(50,50))\n","                    new_img=new_img.reshape(-1,50,50,1)\n","                    predict=model.predict(new_img)\n","                    test_data.append([j,predict])\n","\n","create_test_data()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpnsAO0ci4Ux"},"source":["image=[]\n","classname=[]\n","for i,j in test_data:\n","    classname.append(np.argmax(j))\n","    image.append(i)\n","df=pd.DataFrame(columns=['image','classname'])\n","df['image']=image\n","df['classname']=classname\n","df['classname']=lbl.inverse_transform(df['classname'])\n","image=[]\n","x1=[]\n","x2=[]\n","y1=[]\n","y2=[]\n","for i in df['image']:\n","    image.append(i[0])\n","    x1.append(i[1][0])\n","    x2.append(i[1][1])\n","    y1.append(i[1][2])\n","    y2.append(i[1][3])\n","df['name']=image\n","df['x1']=x1\n","df['x2']=x2\n","df['y1']=y1\n","df['y2']=y2    \n","df.drop(['image'],axis=1,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUTEjF5ji5jK"},"source":["df.sort_values('name',axis=0,inplace=True,ascending=False)\n","df.to_csv('submission_1.csv')"],"execution_count":null,"outputs":[]}]}